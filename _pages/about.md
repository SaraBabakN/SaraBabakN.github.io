---
permalink: /
title: "Sara Babakniya"
excerpt: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About
------
I am a 5th-year Ph.D. student studying Computer Science at the [University of Southern California](https://www.cs.usc.edu/). I am a member of [Information Theory and Machine Learning (vITAL) research lab](https://www.avestimehr.com/vital-lab/) under the supervision of [Prof. Salman Avestimehr](https://www.avestimehr.com/).  Generally, I am interested in Privacy and fairness in ML, Federated Learning, and Neural Network Architecture Search. My recent focus has been on privacy and efficiency in Machine Learning.  
  
I finished my B.Sc. in [Electrical Engineering](http://ee.sharif.edu/~web/en/) at the [Sharif University of Technology](http://www.en.sharif.edu/) in 2019, during which I gained some experience in implementing and designing networked systems.

Experience
-----
Graduate Research Assistant (Aug 2019 - Present)

Publications
-----
- **A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks**  
  <u>Sara Babakniya</u>, Zalan Fabian, Chaoyang He, Mahdi Soltanolkotab and Salman Avestimehr  
  NeurIPS 2023  
  \[[Paper](https://arxiv.org/abs/2311.07784)\], \[[Code](https://github.com/SaraBabakN/MFCL-NeurIPS23)\]
  
- **Revisiting Sparsity Hunting in Federated Learning: Why does Sparsity Consensus Matter?**  
  <u>Sara Babakniya</u>\*, Souvik Kundu\*, Saurav Prakash, Yue Niu and Salman Avestimehr  
  Transactions on Machine Learning Research 2023  
  \[[Paper](https://arxiv.org/abs/2208.13092)\], \[[Code](https://github.com/SaraBabakN/flash_fl)\]  

- **SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models**  
  <u>Sara Babakniya</u>\*, Ahmed Roushdy Elkordy\*, Yahya H Ezzeldin, Qingfeng Liu, Kee-Bong Song, Mostafa El-Khamy, Salman Avestimehr  
  FL@FM-NeurIPS 2023  
  <span style="color:red;">Best Paper Award</span>  
  \[[Paper](https://arxiv.org/pdf/2308.06522)\]
- **Donâ€™t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory**  
  <u>Sara Babakniya</u>, Zalan Fabian, Chaoyang He, Mahdi Soltanolkotab and Salman Avestimehr  
  ICML-FL 2023  
  \[[Paper](https://arxiv.org/pdf/2307.00497)\]

- **Federated Sparse Training: Lottery Aware Model Compression for Resource Constrained Edge**  
  <u>Sara Babakniya</u>\*, Souvik Kundu\*, Saurav Prakash, Yue Niu and Salman Avestimehr  
  NeurIPS-FL 2022  
  \[[Paper](https://arxiv.org/abs/2208.13092)\]

- **Defending Against Poisoning Backdoor Attacks on Federated Meta-Learning**  
  Chien-Lun Chen, <u>Sara Babakniya</u>, Marco Paolieri, and Leana Golubchik  
  ACM Transactions on Intelligent Systems and Technology, 2022  
  \[[Paper](https://par.nsf.gov/servlets/purl/10345295)\]
  
- **Deep-n-Cheap: An Automated Efficient and Extensible Search Framework for Cost-Effective Deep Learning**  
  Sourya Dey, <u>Sara Babakniya</u>, Saikrishna C. Kanala, Marco Paolieri, Leana Golubchik, Peter A. Beerel, and Keith M. Chugg  
  Springer Nature Computer Science, 2021  
  \[[Paper](https://link.springer.com/article/10.1007/s42979-021-00646-0)\], \[[Code](https://github.com/usc-hal/deep-n-cheap/tree/nlp)\]  

Honors and Awards
-----
- Best Paper Award, FL@FM-NeurIPS Workshop, 2023
- Outstanding Poster Presentation, USC MHI Research Festival, 2023
- Best Poster Presentation, USC-Meta Center Workshop, 2022
- Grace Hopper Celebration Travel Grant, USC 2022
- Grad Cohort Travel Grant, CRA-W 2022
- WiSE Qualcomm Top-Off Fellowship 2021
- Grace Hopper Celebration Scholarship 2021

Contact
-----
Email: babakniy[at]usc[dot]edu  
  
University of Southern California  
Department of Computer Science  
Los Angeles, CA 90089-0781  

                                                          last update 7/24/2023
